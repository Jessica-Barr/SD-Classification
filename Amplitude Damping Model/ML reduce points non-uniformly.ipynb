{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40325a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt('Data/Xtrainx.csv', delimiter=',') #load data for sigmax \n",
    "labels = np.loadtxt('Data/Ytrain.csv', delimiter=',') #load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original trajectories contain 20001 time points. At t=0 and t = 0.0005 all of the signals are equal to 1, so \n",
    "#we omit the first time step.\n",
    "X = x[:, 1:x.shape[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9af492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to perform the non-uniform discrete fourier transform. arr is an array containing the time signal, t \n",
    "#is an array containing the associated times\n",
    "def nudft(arr, t):\n",
    "    \n",
    "    N = len(arr)\n",
    "    \n",
    "    #scaling the times to fall between 0 and 1\n",
    "    tscaled = (t - np.amin(t))/(np.amax(t) - np.amin(t))\n",
    "    \n",
    "    #an array to store the Fourier coefficients\n",
    "    coeff = np.zeros(len(arr), dtype=complex)\n",
    "    \n",
    "    #Generating an array of frequencies\n",
    "    freq = np.arange(0, N, 1)\n",
    "    \n",
    "    #calculating the Fourier coefficients\n",
    "    for i in range(len(freq)):\n",
    "        for j in range(len(arr)):\n",
    "            coeff[i] += arr[j]*cmath.exp(-2*np.pi*1j*freq[i]*tscaled[j])\n",
    "            \n",
    "    return(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc064d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to take X and Y and return a training, test and validation set containing the Fourier coefficients\n",
    "#obtained using the non-uniform discrete Fourier transform, along with the corresponding labels. times is an array\n",
    "#of times corresponding to the trajectories in the training, validation and test sets.\n",
    "def nufouriertrainvaltest(X, Y, times):\n",
    "    \n",
    "    #generating a training validation and test set.\n",
    "    Xtrain = X[0:X.shape[0]-600, :]\n",
    "    Xval = X[X.shape[0]-600:X.shape[0]-300, :]\n",
    "    Xtest = X[X.shape[0]-300:X.shape[0], :]\n",
    "    \n",
    "    #The last 3 columns of Y contain the values of $'\\eta'$, $\\omega_c$ and $s$ so we only use the first three \n",
    "    #columns.\n",
    "    Ytrain = Y[0:Y.shape[0]-600, 0:3]\n",
    "    Yval = Y[Y.shape[0]-600:Y.shape[0]-300, 0:3]\n",
    "    Ytest = Y[Y.shape[0]-300:Y.shape[0], 0:3]\n",
    "    \n",
    "    #Defining arrays to store the Fourier coefficients\n",
    "    XtrainF = np.zeros_like(Xtrain, dtype=complex)\n",
    "    XvalF = np.zeros_like(Xval, dtype = complex)\n",
    "    XtestF = np.zeros_like(Xtest, dtype=complex)\n",
    "    \n",
    "    #Calculating the Fourier coefficients\n",
    "    for i in range(Xtrain.shape[0]):\n",
    "        XtrainF[i,:] = nudft(Xtrain[i,:], times)\n",
    "        \n",
    "    for i in range(Xtest.shape[0]):\n",
    "        XvalF[i,:] = nudft(Xval[i,:], times)\n",
    "        XtestF[i,:] = nudft(Xtest[i,:], times)\n",
    "    \n",
    "    #Splitting the coefficients up into their real and imaginary components\n",
    "    xtrain = np.zeros((XtrainF.shape[0], 2*XtrainF.shape[1]))\n",
    "    xval = np.zeros((XvalF.shape[0], 2*XvalF.shape[1]))\n",
    "    xtest = np.zeros((XtestF.shape[0], 2*XtestF.shape[1]))\n",
    "\n",
    "    for i in range(XtrainF.shape[0]):\n",
    "        for j in range(XtrainF.shape[1]):\n",
    "            xtrain[i, 2*j] = XtrainF[i,j].real\n",
    "            xtrain[i, 2*j + 1] = XtrainF[i,j].imag\n",
    "        \n",
    "        \n",
    "    for i in range(XtestF.shape[0]):\n",
    "        for j in range(XtestF.shape[1]):\n",
    "            xval[i, 2*j] = XvalF[i,j].real\n",
    "            xval[i, 2*j + 1] = XvalF[i,j].imag\n",
    "        \n",
    "            xtest[i, 2*j] = XtestF[i,j].real\n",
    "            xtest[i, 2*j + 1] = XtestF[i,j].imag\n",
    "    \n",
    "    return(xtrain, xval, xtest, Ytrain, Yval, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[0:X.shape[0]-600, :]\n",
    "\n",
    "#defining the correlation matrix\n",
    "corrcoeff = np.zeros((Xtrain.shape[1], Xtrain.shape[1]))\n",
    "\n",
    "for i in range(Xtrain.shape[1]):\n",
    "    for j in range(Xtrain.shape[1]):\n",
    "        #calculating the Pearson correlation coefficient between the ith and jth time point\n",
    "        corrcoeff[i, j] = np.corrcoef(Xtrain[:,i], Xtrain[:,j])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b522a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to sort the elements of an array into descending order and return the sorted values in a list, along \n",
    "#with the corresponding indices. \n",
    "def sortmatrix(arr):\n",
    "    #an array to store the indices that would store each row in descending order\n",
    "    sortedindicesrows = np.zeros((arr.shape[0], arr.shape[1]), dtype=int) \n",
    "    #an array to store the corresponding entries\n",
    "    sortedvalsrows = np.zeros((arr.shape[0], arr.shape[1])) \n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        #finding the indices that would sort each row in descending order\n",
    "        sortedindicesrows[i,:] = (-arr[i,:]).argsort() \n",
    "        #finding the corresponding elements\n",
    "        sortedvalsrows[i,:] = arr[i, sortedindicesrows[i,:]] \n",
    "    \n",
    "    #flattening the array to apply argsort\n",
    "    sortedrowsflat = sortedvalsrows.flatten() \n",
    "    #finding the indices that would sort the flattened array in descending order\n",
    "    indicesflat = (-sortedrowsflat).argsort() \n",
    "    \n",
    "    #defining a list to sore tuples of indices\n",
    "    sortedindices = [] \n",
    "    #defining a list to store the sorted values corresponding to the indices\n",
    "    sortedvals = [] \n",
    "    \n",
    "    #finding the row and column indices in the original array\n",
    "    for i in range(len(indicesflat)):\n",
    "        for j in range(arr.shape[0]):\n",
    "            if(j*arr.shape[1]) <= indicesflat[i] <= ((j+1)*arr.shape[1]-1):\n",
    "                rowindex = j #row index\n",
    "                columnindex = sortedindicesrows[j, indicesflat[i]-j*arr.shape[1]] #column index\n",
    "                \n",
    "                sortedindices.append((int(j), int(columnindex))) #adding tuple to the list of indices\n",
    "                sortedvals.append(arr[int(j), int(columnindex)]) #adding the corresponding element in the array\n",
    "    return(sortedindices, sortedvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the elements in the correlation matrix\n",
    "sortedindices, sortedvals = sortmatrix(np.abs(corrcoeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb18d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = labels[0:labels.shape[0]-600, 0:3]\n",
    "\n",
    "#Finding the trajectories in the training set which correspond to Ohmic, sub-Ohmic and super-Ohmic spectral \n",
    "#densities.\n",
    "subindices = np.where(Ytrain[:,0] == 1)[0]\n",
    "ohmicindices = np.where(Ytrain[:,1] == 1)[0]\n",
    "superindices = np.where(Ytrain[:,2] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the corresponding trajectories \n",
    "xsub = Xtrain[subindices,:]\n",
    "xohmic = Xtrain[ohmicindices,:]\n",
    "xsuper = Xtrain[superindices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d247aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining arrays to store the variance of the time points in the total trainingset, and the variance of the time \n",
    "#points for each class in the training set. We also define an array to store the mean of the class variances for \n",
    "#each time point. \n",
    "variancetot = np.zeros(Xtrain.shape[1])\n",
    "variancesub = np.zeros(Xtrain.shape[1])\n",
    "varianceohmic = np.zeros(Xtrain.shape[1])\n",
    "variancesuper = np.zeros(Xtrain.shape[1])\n",
    "variancemean = np.zeros(X.shape[1])\n",
    "\n",
    "#Calculating the variances \n",
    "for i in range(X.shape[1]):\n",
    "    variancetot[i] = np.std(Xtrain[:,i])**2\n",
    "    variancesub[i] = np.std(xsub[:,i])**2\n",
    "    varianceohmic[i] = np.std(xohmic[:,i])**2\n",
    "    variancesuper[i] = np.std(xsuper[:,i])**2\n",
    "    variancemean[i] = (varianceohmic[i] + variancesub[i] + variancesuper[i])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78631c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining an array to store the difference between the mean of the class variances and the total variance\n",
    "variancediff = np.zeros(X.shape[1])\n",
    "\n",
    "#calculating the difference between the mean of the class variances and the total variance for each feature\n",
    "for i in range(X.shape[1]):\n",
    "    variancediff[i] = variancetot[i] - variancemean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a list to the store the indices to be removed if we are to maintain a high classification accuracy. The \n",
    "#time point corresponding to the first index in the list is to be removed first, and the time point corresponding \n",
    "#to the second index is to be removed next, and so on.\n",
    "removeorder = []\n",
    "\n",
    "#For each of the sorted indices of the correlation matrix\n",
    "for i in range(len(sortedindices)):\n",
    "    truthval = sortedindices[i][0] in removeorder or sortedindices[i][1] in removeorder #will return true if either index is already in the array\n",
    "    #if neither index is already in the list, and the indices are not equal\n",
    "    if truthval == False and sortedindices[i][0] != sortedindices[i][1]:\n",
    "        #if the difference between the total variance and the mean of the class variances for the first index in \n",
    "        #the tuple is less than that for the second index in the tuple \n",
    "        if variancediff[sortedindices[i][0]] < variancediff[sortedindices[i][1]]:\n",
    "            #add the first index to the list\n",
    "            removeorder.append(sortedindices[i][0])\n",
    "        else:\n",
    "            #otherwise add the second\n",
    "            removeorder.append(sortedindices[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the last index to be removed\n",
    "for i in range(X.shape[1]):\n",
    "    if len(np.where(np.array(removeorder)==i)[0]) == 0:\n",
    "        lastindex = i\n",
    "\n",
    "#adding it to the list        \n",
    "removeorder.append(lastindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd41b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining an array containing the number of points to be used in descending order. The accuracy and loss \n",
    "#is to be evaluated when the number of time points in the trajectories is given by each element in the array.\n",
    "npoints = np.array([400, 200, 134, 100, 40, 27, 20, 16, 14, 12, 10, 9, 8, 7, 6, 5, 4, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays to store the final test accuracies\n",
    "testaccuracy = np.zeros(len(npoints))\n",
    "\n",
    "#arrays to store the final test loss\n",
    "testloss = np.zeros(len(npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(npoints)):\n",
    "    \n",
    "    #Finding the indices of the time points to keep in the trajectories \n",
    "    indicestokeep = removeorder[len(removeorder)-npoints[l]:len(removeorder)]\n",
    "    \n",
    "    #defining the data set\n",
    "    data = X[:, np.sort(np.array(indicestokeep))]\n",
    "    \n",
    "    #defining the corresponding times\n",
    "    times = t[np.sort(np.array(indicestokeep))]\n",
    "    \n",
    "    #Generating the training, test and validation set obtained using the non-uniform discrete Fourier transform\n",
    "    Xtrain, Xval, Xtest, Ytrain, Yval, Ytest = nufouriertrainvaltest(data, labels, times)  \n",
    "\n",
    "    #Defining the model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(250, input_dim = (Xtrain.shape[1]), activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(80 , activation = 'sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "    #setting the optimiser equal to the Adam optimiser with learning rate = 0.0001\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "    #compiling the model\n",
    "    model.compile(optimizer=opt,\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['categorical_accuracy'])\n",
    "\n",
    "    #training the model\n",
    "    history = model.fit(Xtrain, Ytrain, epochs = 10000, validation_data = (Xval, Yval), batch_size = Xtrain.shape[0], verbose=0)\n",
    "     \n",
    "    #find the training, validation and test accuracies\n",
    "    testaccuracy[l] = model.evaluate(Xtest, Ytest)[1]\n",
    "    \n",
    "    #finding the loss evaluated on the training, validation and test set\n",
    "    testloss[l] = model.evaluate(Xtest, Ytest)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
